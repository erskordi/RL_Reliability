{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DDPG with PyTorch\n",
    "\n",
    "Same experiment using PyTorch instead of TF\n",
    "\n",
    "Model-free, off-policy RL method.\n",
    "\n",
    "Two networks here:\n",
    " - Actor: Proposes an action\n",
    " - Critic: Evaluates action based on new state, reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import sys\n",
    "import random\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from collections import deque\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F \n",
    "import torch.autograd\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GaussianNoise(nn.Module):\n",
    "    \"\"\"Gaussian noise regularizer.\n",
    "\n",
    "    Args:\n",
    "        sigma (float, optional): relative standard deviation used to generate the\n",
    "            noise. Relative means that it will be multiplied by the magnitude of\n",
    "            the value your are adding the noise to. This means that sigma can be\n",
    "            the same regardless of the scale of the vector.\n",
    "        is_relative_detach (bool, optional): whether to detach the variable before\n",
    "            computing the scale of the noise. If `False` then the scale of the noise\n",
    "            won't be seen as a constant but something to optimize: this will bias the\n",
    "            network to generate vectors with smaller values.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, sigma=.1, is_relative_detach=False):\n",
    "        super().__init__()\n",
    "        self.sigma = sigma\n",
    "        self.is_relative_detach = is_relative_detach\n",
    "        self.noise = torch.tensor(0)#.to(device)\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.training and self.sigma != 0:\n",
    "            scale = self.sigma * x.detach() if self.is_relative_detach else self.sigma * x\n",
    "            sampled_noise = self.noise.repeat(*x.size()).float().normal_() * scale\n",
    "            x = x + sampled_noise\n",
    "        return x \n",
    "\n",
    "class Critic(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(Critic, self).__init__()\n",
    "        self.linear1 = nn.Linear(input_size, hidden_size)\n",
    "        self.linear2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.linear3 = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, state, action):\n",
    "        \"\"\"\n",
    "        Params state and actions are torch tensors\n",
    "        \"\"\"\n",
    "        x = torch.cat([state, action], 1)\n",
    "        x = F.relu(self.linear1(x))\n",
    "        x = F.relu(self.linear2(x))\n",
    "        x = self.linear3(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "class Actor(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, learning_rate = 3e-4):\n",
    "        super(Actor, self).__init__()\n",
    "        self.output_size = output_size\n",
    "        self.linear1 = nn.Linear(input_size, hidden_size)\n",
    "        self.linear2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.linear3 = nn.Linear(hidden_size, output_size)\n",
    "        torch.nn.init.uniform_(self.linear3.weight, a=0.1, b=0.5)\n",
    "        \n",
    "        self.noise = GaussianNoise()\n",
    "        \n",
    "    def forward(self, state, noise=False):\n",
    "        \"\"\"\n",
    "        Param state is a torch tensor\n",
    "        \"\"\"\n",
    "        x = F.relu(self.linear1(state))\n",
    "        x = F.relu(self.linear2(x))\n",
    "        x = torch.sigmoid(self.linear3(x))\n",
    "        \n",
    "        if noise:\n",
    "            return self.noise.forward(x)\n",
    "        else:\n",
    "            return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Memory:\n",
    "    def __init__(self, max_size):\n",
    "        self.max_size = max_size\n",
    "        self.buffer = deque(maxlen=max_size)\n",
    "    \n",
    "    def push(self, state, action, reward, next_state, done):\n",
    "        experience = (state, action, np.array([reward]), next_state, done)\n",
    "        self.buffer.append(experience)\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        state_batch = []\n",
    "        action_batch = []\n",
    "        reward_batch = []\n",
    "        next_state_batch = []\n",
    "        done_batch = []\n",
    "\n",
    "        batch = random.sample(self.buffer, batch_size)\n",
    "\n",
    "        for experience in batch:\n",
    "            state, action, reward, next_state, done = experience\n",
    "            state_batch.append(state)\n",
    "            action_batch.append(action)\n",
    "            reward_batch.append(reward)\n",
    "            next_state_batch.append(next_state)\n",
    "            done_batch.append(done)\n",
    "        \n",
    "        return state_batch, action_batch, reward_batch, next_state_batch, done_batch\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "### DDPG Agent\n",
    "\n",
    "class DDPGagent:\n",
    "    def __init__(self, env_obs, env_acts, hidden_size=256, actor_learning_rate=1e-4, critic_learning_rate=1e-3,\\\n",
    "                 gamma=0.99, tau=0.005, max_memory_size=50000):\n",
    "        # Params\n",
    "        self.num_states = env_obs\n",
    "        self.num_actions = env_acts\n",
    "        self.gamma = gamma\n",
    "        self.tau = tau\n",
    "        \n",
    "        # Networks\n",
    "        self.actor = Actor(self.num_states, hidden_size, self.num_actions)\n",
    "        self.actor_target = Actor(self.num_states, hidden_size, self.num_actions)\n",
    "        self.critic = Critic(self.num_states + self.num_actions, hidden_size, self.num_actions)\n",
    "        self.critic_target = Critic(self.num_states + self.num_actions, hidden_size, self.num_actions)\n",
    "\n",
    "        for target_param, param in zip(self.actor_target.parameters(), self.actor.parameters()):\n",
    "            target_param.data.copy_(param.data)\n",
    "\n",
    "        for target_param, param in zip(self.critic_target.parameters(), self.critic.parameters()):\n",
    "            target_param.data.copy_(param.data)\n",
    "        \n",
    "        # Training\n",
    "        self.memory = Memory(max_memory_size)        \n",
    "        self.critic_criterion  = nn.MSELoss()\n",
    "        self.actor_optimizer  = optim.Adam(self.actor.parameters(), lr=actor_learning_rate)\n",
    "        self.critic_optimizer = optim.Adam(self.critic.parameters(), lr=critic_learning_rate)\n",
    "    \n",
    "    def get_action(self, state, noise):\n",
    "        state = np.array(state)\n",
    "        state = Variable(torch.from_numpy(state).float().unsqueeze(0))\n",
    "        action = self.actor.forward(state, noise)\n",
    "        action = action\n",
    "\n",
    "        return np.squeeze(action)\n",
    "    \n",
    "    def update(self, batch_size, path_to_save=[]):\n",
    "        states, actions, rewards, next_states, _ = self.memory.sample(batch_size)\n",
    "        states = torch.FloatTensor(states)\n",
    "        actions = torch.FloatTensor(actions)\n",
    "        rewards = torch.FloatTensor(rewards)\n",
    "        next_states = torch.FloatTensor(next_states)\n",
    "    \n",
    "        # Critic loss        \n",
    "        Qvals = self.critic.forward(states, actions)\n",
    "        next_actions = self.actor_target.forward(next_states)\n",
    "        \n",
    "        next_Q = self.critic_target.forward(next_states, next_actions.detach())\n",
    "       \n",
    "        Qprime = rewards + self.gamma * next_Q\n",
    "        critic_loss = self.critic_criterion(Qvals, Qprime)\n",
    "\n",
    "        # Actor loss\n",
    "        policy_loss = -self.critic.forward(states, self.actor.forward(states)).mean()\n",
    "        \n",
    "        \n",
    "        # update networks\n",
    "        self.actor_optimizer.zero_grad()\n",
    "        policy_loss.backward()\n",
    "        self.actor_optimizer.step()\n",
    "\n",
    "        self.critic_optimizer.zero_grad()\n",
    "        critic_loss.backward() \n",
    "        self.critic_optimizer.step()\n",
    "\n",
    "        # update target networks \n",
    "        for target_param, param in zip(self.actor_target.parameters(), self.actor.parameters()):\n",
    "            target_param.data.copy_(param.data * self.tau + target_param.data * (1.0 - self.tau))\n",
    "       \n",
    "        for target_param, param in zip(self.critic_target.parameters(), self.critic.parameters()):\n",
    "            target_param.data.copy_(param.data * self.tau + target_param.data * (1.0 - self.tau))\n",
    "        \n",
    "        if len(path_to_save) > 0:\n",
    "            torch.save(self.actor, path_to_save[0])\n",
    "            torch.save(self.critic, path_to_save[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Run training\n",
    "\n",
    "def cross_validation(agent, env, iteration):\n",
    "    batch_size = 8\n",
    "    rewards = []\n",
    "    avg_rewards = []\n",
    "    exploitation_rewards = []\n",
    "    total_rewards = []\n",
    "    num_episodes = 100\n",
    "    action_history = []\n",
    "    \n",
    "    for episode in range(num_episodes):\n",
    "        state = env.reset()\n",
    "        episode_reward = 0\n",
    "        episode_info = {}\n",
    "        \n",
    "\n",
    "        while True:\n",
    "            action = agent.get_action(state, noise=True) # Gets action from DDPG agent\n",
    "            action = np.asarray([np.squeeze(action.detach().numpy())])\n",
    "            if episode % 5 == 0 and episode > 0:\n",
    "                action = agent.get_action(state, noise=False)\n",
    "                action = np.asarray([np.squeeze(action.detach().numpy())])\n",
    "            new_state, reward, done, info = env.step(action) \n",
    "            episode_info['reward'] = reward\n",
    "            agent.memory.push(state, action, reward, new_state, done)\n",
    "\n",
    "            if len(agent.memory) > batch_size and episode < num_episodes-1:\n",
    "                agent.update(batch_size)  \n",
    "            elif len(agent.memory) > batch_size and episode == num_episodes-1:\n",
    "                agent.update(batch_size, path_to_save=[\"./saved_models/trained_actor.pt\",\n",
    "                                                       \"./saved_models/trained_critic.pt\"])\n",
    "\n",
    "            state = new_state\n",
    "            episode_reward += reward\n",
    "            action_history.append(action.squeeze())\n",
    "\n",
    "            if done:\n",
    "                break\n",
    "\n",
    "        rewards.append(episode_reward)\n",
    "        avg_rewards.append(np.mean(rewards[-50:]))\n",
    "        if episode % 5 == 0 and episode > 0:\n",
    "            exploitation_rewards.append(episode_reward)\n",
    "        \n",
    "    data = {'Rewards':rewards,\n",
    "           'Avg_rewards':avg_rewards}\n",
    "    results = pd.DataFrame(data)        \n",
    "    \n",
    "    return results, action_history, exploitation_rewards"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ray import serve\n",
    "\n",
    "from config import Config\n",
    "from data_prep import DataPrep\n",
    "from env_no_serve import CMAPSSEnv\n",
    "from tf_decoder_model import TFDecoderModel\n",
    "from VAE_dense import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "const = Config()\n",
    "neurons = const.VAE_neurons\n",
    "\n",
    "# Data prep\n",
    "data = DataPrep(file = const.file_path,\n",
    "                num_settings = const.num_settings,\n",
    "                num_sensors = const.num_sensors,\n",
    "                num_units = const.num_units[1],\n",
    "                prev_step_units = const.prev_step_units[1],\n",
    "                step = const.step[1],\n",
    "                normalization_type=\"01\")\n",
    "\n",
    "df = data.ReadData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of State Space ->  25\n",
      "Size of Action Space ->  1\n",
      "1.0 0.0\n"
     ]
    }
   ],
   "source": [
    "# List of engine lifetimes\n",
    "engine_lives = df.groupby(df['Unit']).size().tolist()\n",
    "num_engines = len(engine_lives)\n",
    "\n",
    "# Load decoder\n",
    "decoder = tf.keras.models.load_model('./saved_models/decoder', compile=False)\n",
    "\n",
    "# Environment types\n",
    "env_types = [\"batch\", \"intertemporal\"]\n",
    "\n",
    "##########################################\n",
    "env_config = {\n",
    "    \"df\": df,\n",
    "    \"timestep\": 0,\n",
    "    \"obs_size\": const.num_settings+const.num_sensors+1,\n",
    "    \"engines\": num_engines,\n",
    "    \"engine_lives\": engine_lives, \n",
    "    \"decoder_model\": decoder,\n",
    "    \"env_type\": env_types[0],\n",
    "}\n",
    "\n",
    "env = CMAPSSEnv(**env_config)\n",
    "\n",
    "num_states = env.observation_space.shape[0]\n",
    "print(\"Size of State Space ->  {}\".format(num_states))\n",
    "num_actions = env.action_space.shape[0]\n",
    "print(\"Size of Action Space ->  {}\".format(num_actions))\n",
    "\n",
    "upper_bound = env.action_space.high[0]\n",
    "lower_bound = env.action_space.low[0]\n",
    "\n",
    "print(upper_bound, lower_bound)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "agent = DDPGagent(env.observation_space.shape[0],env.action_space.shape[0])\n",
    "results, action_history, exploitation_rewards = cross_validation(agent, env, iteration=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plot results\n",
    "plt.plot(results['Avg_rewards'])\n",
    "plt.title(r'Average rewards $\\sigma=0.1$')\n",
    "plt.xlabel('Episode')\n",
    "plt.ylabel('Reward')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(exploitation_rewards)\n",
    "plt.title(r'Noise-free rewards $\\sigma=0.1$')\n",
    "plt.xlabel('Episode')\n",
    "plt.ylabel('Reward')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unit</th>\n",
       "      <th>NormTime</th>\n",
       "      <th>OpSetting1</th>\n",
       "      <th>OpSetting2</th>\n",
       "      <th>OpSetting3</th>\n",
       "      <th>Sensor1</th>\n",
       "      <th>Sensor2</th>\n",
       "      <th>Sensor3</th>\n",
       "      <th>Sensor4</th>\n",
       "      <th>Sensor5</th>\n",
       "      <th>...</th>\n",
       "      <th>Sensor12</th>\n",
       "      <th>Sensor13</th>\n",
       "      <th>Sensor14</th>\n",
       "      <th>Sensor15</th>\n",
       "      <th>Sensor16</th>\n",
       "      <th>Sensor17</th>\n",
       "      <th>Sensor18</th>\n",
       "      <th>Sensor19</th>\n",
       "      <th>Sensor20</th>\n",
       "      <th>Sensor21</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>211</td>\n",
       "      <td>0.995327</td>\n",
       "      <td>0.833248</td>\n",
       "      <td>0.997625</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.060269</td>\n",
       "      <td>0.187903</td>\n",
       "      <td>0.333902</td>\n",
       "      <td>0.225908</td>\n",
       "      <td>0.146592</td>\n",
       "      <td>...</td>\n",
       "      <td>0.136443</td>\n",
       "      <td>0.993796</td>\n",
       "      <td>0.564038</td>\n",
       "      <td>0.343278</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.308511</td>\n",
       "      <td>0.651163</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.163861</td>\n",
       "      <td>0.165210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>211</td>\n",
       "      <td>0.990654</td>\n",
       "      <td>0.999919</td>\n",
       "      <td>0.997862</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.133493</td>\n",
       "      <td>0.286198</td>\n",
       "      <td>0.207650</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003173</td>\n",
       "      <td>0.993658</td>\n",
       "      <td>0.599009</td>\n",
       "      <td>0.367114</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.287234</td>\n",
       "      <td>0.627907</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.017863</td>\n",
       "      <td>0.021717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>211</td>\n",
       "      <td>0.985981</td>\n",
       "      <td>0.476059</td>\n",
       "      <td>0.833017</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.626985</td>\n",
       "      <td>0.662033</td>\n",
       "      <td>0.643966</td>\n",
       "      <td>0.535748</td>\n",
       "      <td>0.507937</td>\n",
       "      <td>...</td>\n",
       "      <td>0.473287</td>\n",
       "      <td>0.993824</td>\n",
       "      <td>0.548079</td>\n",
       "      <td>0.321170</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.638298</td>\n",
       "      <td>0.864693</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.494675</td>\n",
       "      <td>0.493584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>211</td>\n",
       "      <td>0.981308</td>\n",
       "      <td>0.999781</td>\n",
       "      <td>0.997625</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.130731</td>\n",
       "      <td>0.302533</td>\n",
       "      <td>0.234678</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004391</td>\n",
       "      <td>0.993769</td>\n",
       "      <td>0.594056</td>\n",
       "      <td>0.364319</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.276596</td>\n",
       "      <td>0.627907</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.014772</td>\n",
       "      <td>0.018016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>211</td>\n",
       "      <td>0.976636</td>\n",
       "      <td>0.833160</td>\n",
       "      <td>0.997625</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.060269</td>\n",
       "      <td>0.184588</td>\n",
       "      <td>0.324665</td>\n",
       "      <td>0.235570</td>\n",
       "      <td>0.146592</td>\n",
       "      <td>...</td>\n",
       "      <td>0.136621</td>\n",
       "      <td>0.994045</td>\n",
       "      <td>0.563088</td>\n",
       "      <td>0.344013</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.297872</td>\n",
       "      <td>0.651163</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.154930</td>\n",
       "      <td>0.160667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10266</th>\n",
       "      <td>260</td>\n",
       "      <td>0.012658</td>\n",
       "      <td>0.476188</td>\n",
       "      <td>0.831354</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.626985</td>\n",
       "      <td>0.674461</td>\n",
       "      <td>0.682297</td>\n",
       "      <td>0.591067</td>\n",
       "      <td>0.507937</td>\n",
       "      <td>...</td>\n",
       "      <td>0.468871</td>\n",
       "      <td>0.996250</td>\n",
       "      <td>0.803507</td>\n",
       "      <td>0.351775</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.691489</td>\n",
       "      <td>0.864693</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.485400</td>\n",
       "      <td>0.482746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10267</th>\n",
       "      <td>260</td>\n",
       "      <td>0.009494</td>\n",
       "      <td>0.238102</td>\n",
       "      <td>0.298100</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.597937</td>\n",
       "      <td>0.647026</td>\n",
       "      <td>0.733008</td>\n",
       "      <td>0.726354</td>\n",
       "      <td>0.617180</td>\n",
       "      <td>...</td>\n",
       "      <td>0.613969</td>\n",
       "      <td>0.994596</td>\n",
       "      <td>0.992921</td>\n",
       "      <td>0.151333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.744681</td>\n",
       "      <td>0.854123</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.613878</td>\n",
       "      <td>0.621748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10268</th>\n",
       "      <td>260</td>\n",
       "      <td>0.006329</td>\n",
       "      <td>0.595222</td>\n",
       "      <td>0.736342</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.238089</td>\n",
       "      <td>0.017952</td>\n",
       "      <td>0.088067</td>\n",
       "      <td>0.066888</td>\n",
       "      <td>0.293184</td>\n",
       "      <td>...</td>\n",
       "      <td>0.087384</td>\n",
       "      <td>0.007279</td>\n",
       "      <td>0.307234</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.063830</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.136036</td>\n",
       "      <td>0.140835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10269</th>\n",
       "      <td>260</td>\n",
       "      <td>0.003165</td>\n",
       "      <td>0.595203</td>\n",
       "      <td>0.738717</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.238089</td>\n",
       "      <td>0.021267</td>\n",
       "      <td>0.079155</td>\n",
       "      <td>0.087648</td>\n",
       "      <td>0.293184</td>\n",
       "      <td>...</td>\n",
       "      <td>0.088983</td>\n",
       "      <td>0.007334</td>\n",
       "      <td>0.310286</td>\n",
       "      <td>0.995586</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.074468</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.131226</td>\n",
       "      <td>0.130673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10270</th>\n",
       "      <td>260</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.833260</td>\n",
       "      <td>0.997625</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.060269</td>\n",
       "      <td>0.194347</td>\n",
       "      <td>0.354544</td>\n",
       "      <td>0.283902</td>\n",
       "      <td>0.146592</td>\n",
       "      <td>...</td>\n",
       "      <td>0.136494</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.842806</td>\n",
       "      <td>0.387199</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.361702</td>\n",
       "      <td>0.651163</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.155273</td>\n",
       "      <td>0.157694</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10271 rows Ã— 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unit  NormTime  OpSetting1  OpSetting2  OpSetting3   Sensor1   Sensor2  \\\n",
       "0       211  0.995327    0.833248    0.997625         1.0  0.060269  0.187903   \n",
       "1       211  0.990654    0.999919    0.997862         1.0  0.000000  0.133493   \n",
       "2       211  0.985981    0.476059    0.833017         1.0  0.626985  0.662033   \n",
       "3       211  0.981308    0.999781    0.997625         1.0  0.000000  0.130731   \n",
       "4       211  0.976636    0.833160    0.997625         1.0  0.060269  0.184588   \n",
       "...     ...       ...         ...         ...         ...       ...       ...   \n",
       "10266   260  0.012658    0.476188    0.831354         1.0  0.626985  0.674461   \n",
       "10267   260  0.009494    0.238102    0.298100         1.0  0.597937  0.647026   \n",
       "10268   260  0.006329    0.595222    0.736342         0.0  0.238089  0.017952   \n",
       "10269   260  0.003165    0.595203    0.738717         0.0  0.238089  0.021267   \n",
       "10270   260  0.000000    0.833260    0.997625         1.0  0.060269  0.194347   \n",
       "\n",
       "        Sensor3   Sensor4   Sensor5  ...  Sensor12  Sensor13  Sensor14  \\\n",
       "0      0.333902  0.225908  0.146592  ...  0.136443  0.993796  0.564038   \n",
       "1      0.286198  0.207650  0.000000  ...  0.003173  0.993658  0.599009   \n",
       "2      0.643966  0.535748  0.507937  ...  0.473287  0.993824  0.548079   \n",
       "3      0.302533  0.234678  0.000000  ...  0.004391  0.993769  0.594056   \n",
       "4      0.324665  0.235570  0.146592  ...  0.136621  0.994045  0.563088   \n",
       "...         ...       ...       ...  ...       ...       ...       ...   \n",
       "10266  0.682297  0.591067  0.507937  ...  0.468871  0.996250  0.803507   \n",
       "10267  0.733008  0.726354  0.617180  ...  0.613969  0.994596  0.992921   \n",
       "10268  0.088067  0.066888  0.293184  ...  0.087384  0.007279  0.307234   \n",
       "10269  0.079155  0.087648  0.293184  ...  0.088983  0.007334  0.310286   \n",
       "10270  0.354544  0.283902  0.146592  ...  0.136494  1.000000  0.842806   \n",
       "\n",
       "       Sensor15  Sensor16  Sensor17  Sensor18  Sensor19  Sensor20  Sensor21  \n",
       "0      0.343278       0.0  0.308511  0.651163       1.0  0.163861  0.165210  \n",
       "1      0.367114       0.0  0.287234  0.627907       1.0  0.017863  0.021717  \n",
       "2      0.321170       0.0  0.638298  0.864693       1.0  0.494675  0.493584  \n",
       "3      0.364319       0.0  0.276596  0.627907       1.0  0.014772  0.018016  \n",
       "4      0.344013       0.0  0.297872  0.651163       1.0  0.154930  0.160667  \n",
       "...         ...       ...       ...       ...       ...       ...       ...  \n",
       "10266  0.351775       1.0  0.691489  0.864693       1.0  0.485400  0.482746  \n",
       "10267  0.151333       1.0  0.744681  0.854123       1.0  0.613878  0.621748  \n",
       "10268  1.000000       0.0  0.063830  0.000000       0.0  0.136036  0.140835  \n",
       "10269  0.995586       0.0  0.074468  0.000000       0.0  0.131226  0.130673  \n",
       "10270  0.387199       0.0  0.361702  0.651163       1.0  0.155273  0.157694  \n",
       "\n",
       "[10271 rows x 26 columns]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test data\n",
    "t_data = DataPrep(file = const.file_path,\n",
    "                num_settings = const.num_settings,\n",
    "                num_sensors = const.num_sensors,\n",
    "                num_units = const.num_units[2],\n",
    "                prev_step_units = const.prev_step_units[2],\n",
    "                step = const.step[2],\n",
    "                normalization_type=\"01\")\n",
    "\n",
    "test_df = t_data.ReadData()\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[214, 149, 196, 146, 226, 229, 162, 237, 156, 234, 178, 195, 218, 174, 156, 178, 184, 262, 176, 186, 144, 242, 190, 159, 183, 239, 209, 156, 263, 266, 183, 273, 230, 128, 253, 194, 197, 234, 202, 184, 266, 135, 149, 260, 340, 163, 309, 143, 205, 316] 50\n"
     ]
    }
   ],
   "source": [
    "# List of engine lifetimes\n",
    "engine_lives = test_df.groupby(test_df['Unit']).size()\n",
    "engine_lives = engine_lives.tolist()\n",
    "num_engines = len(engine_lives)\n",
    "\n",
    "print(engine_lives, num_engines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################\n",
    "env_config = {\n",
    "    \"df\": test_df,\n",
    "    \"timestep\": 0,\n",
    "    \"obs_size\": const.num_settings+const.num_sensors+1,\n",
    "    \"engines\": num_engines,\n",
    "    \"engine_lives\": engine_lives, \n",
    "    \"decoder_model\": decoder,\n",
    "    \"env_type\": env_types[0],\n",
    "}\n",
    "\n",
    "#print(\"env_config: \", env_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "actor = torch.load(\"trained_actor.pt\")\n",
    "\n",
    "est_rul = []\n",
    "est_sensor1 = []\n",
    "action_vector = []\n",
    "\n",
    "#for s in range(len(test_df)):\n",
    "obs = env.reset()\n",
    "for t in range(engine_lives[0]):\n",
    "    action = actor.forward(torch.FloatTensor(obs))\n",
    "    action = np.asarray([np.squeeze(action.detach().numpy())])\n",
    "    action_vector.append(action)\n",
    "    obs, _, _, _ = env.step(action)\n",
    "    est_rul.append(obs[0])\n",
    "    est_sensor1.append(obs[5])\n",
    "    #print(rew, done)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(est_sensor1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
